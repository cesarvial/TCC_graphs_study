{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demonstração Graph Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ganrante que as bibliotecas necessárias estrão disponíveis no jupyter\n",
    "# %conda install -c pytorch pytorch torchvision\n",
    "# %conda install pyg -c pyg -c conda-forge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recursos básicos da Pytorch Geometric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[3, 1], edge_index=[2, 4])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Somente para imprimir imagens locais no jupyter-notebook\n",
    "from IPython import display\n",
    "\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "edge_index = torch.tensor([[0, 1, 1, 2],\n",
    "                           [1, 0, 2, 1]], dtype=torch.long)\n",
    "x = torch.tensor([[-1], [0], [1]], dtype=torch.float)\n",
    "\n",
    "data = Data(x=x, edge_index=edge_index)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display.Image(\"imgs/grafosimples.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### O objeto Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method BaseData.keys of Data(x=[3, 1], edge_index=[2, 4])>\n",
      "\n",
      "tensor([[-1.],\n",
      "        [ 0.],\n",
      "        [ 1.]])\n",
      "\n",
      "x presente no grafo\n",
      "edge_index presente no grafo\n"
     ]
    }
   ],
   "source": [
    "print(data.keys)\n",
    "\n",
    "print()\n",
    "print(data['x'])\n",
    "\n",
    "print()\n",
    "for key, item in data:\n",
    "    print(key+\" presente no grafo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "print(data.num_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "1\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "print(data.num_edges)\n",
    "\n",
    "\n",
    "print(data.num_node_features)\n",
    "\n",
    "\n",
    "print(data.has_isolated_nodes())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tranferir o objeto data para a GPU.\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "data = data.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datasets prontos disponíveis na Pytorch Geometric\n",
    "Existem vários datasets já disponíveis. É útil olhar para esses \"formatados\", pois podemos entender como os nossos datasets podem estar depois de carregados apropriadamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ENZYMES(600)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch_geometric.datasets import TUDataset\n",
    "\n",
    "dataset = TUDataset(root='/tmp/ENZYMES', name='ENZYMES')\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "600"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(edge_index=[2, 160], x=[67, 3], y=[1])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[500]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.num_classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.num_node_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se necessário, podemos embaralhar o dataset\n",
    "dataset = dataset.shuffle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ENZYMES(500)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Podemos fatiar o dataset\n",
    "train_dataset = dataset[:500]\n",
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ENZYMES(100)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset = dataset[500:]\n",
    "test_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exemplo de dataset com um único grafo\n",
    "Este exemplo ilustra um grafo para os problemas de classificação de nós"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Cora()"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch_geometric.datasets import Planetoid\n",
    "\n",
    "dataset = Planetoid(root='/tmp/Cora', name='Cora')\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "7\n",
      "1433\n"
     ]
    }
   ],
   "source": [
    "print(len(dataset))\n",
    "\n",
    "print(dataset.num_classes)\n",
    "\n",
    "print(dataset.num_node_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[2708, 1433], edge_index=[2, 10556], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = dataset[0]\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veja que tem os campos train_mask, val_mask e test_mask. Isso facilita a realização do treinamento e testes. <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140\n",
      "500\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "print(data.train_mask.sum().item())\n",
    "\n",
    "print(data.val_mask.sum().item())\n",
    "\n",
    "print(data.test_mask.sum().item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train_mask: indica quais nós serão usados para treinar (140 nós)<br>\n",
    "\n",
    "val_mask: nós para validação (500 nós),\n",
    "\n",
    "test_mask: quais nós para testar (1000 nós)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mini-batches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abordagem comum em redes neurais.\n",
    "\n",
    "PyG contém seu próprio torch_geometric.loader.DataLoader, que já cuida desse processo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataBatch(edge_index=[2, 11720], x=[3042, 21], y=[100], batch=[3042], ptr=[101])\n",
      "Numero de grafos:100\n",
      "tensor([ 0,  0,  0,  ..., 99, 99, 99])\n",
      "\n",
      "DataBatch(edge_index=[2, 12132], x=[3277, 21], y=[100], batch=[3277], ptr=[101])\n",
      "Numero de grafos:100\n",
      "tensor([ 0,  0,  0,  ..., 99, 99, 99])\n",
      "\n",
      "DataBatch(edge_index=[2, 12764], x=[3312, 21], y=[100], batch=[3312], ptr=[101])\n",
      "Numero de grafos:100\n",
      "tensor([ 0,  0,  0,  ..., 99, 99, 99])\n",
      "\n",
      "DataBatch(edge_index=[2, 11990], x=[3180, 21], y=[100], batch=[3180], ptr=[101])\n",
      "Numero de grafos:100\n",
      "tensor([ 0,  0,  0,  ..., 99, 99, 99])\n",
      "\n",
      "DataBatch(edge_index=[2, 12406], x=[3257, 21], y=[100], batch=[3257], ptr=[101])\n",
      "Numero de grafos:100\n",
      "tensor([ 0,  0,  0,  ..., 99, 99, 99])\n",
      "\n",
      "DataBatch(edge_index=[2, 13552], x=[3512, 21], y=[100], batch=[3512], ptr=[101])\n",
      "Numero de grafos:100\n",
      "tensor([ 0,  0,  0,  ..., 99, 99, 99])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.datasets import TUDataset\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "dataset = TUDataset(root='/tmp/ENZYMES', name='ENZYMES', use_node_attr=True)\n",
    "loader = DataLoader(dataset, batch_size=100, shuffle=True)\n",
    "\n",
    "for batch in loader:\n",
    "    print(batch)\n",
    "    print(\"Numero de grafos:\"+str(batch.num_graphs))\n",
    "    \n",
    "    #O atributo batch é um vetor que indica em que grafo cada nó pertence\n",
    "    print(batch.batch)\n",
    "    print()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O atributo batch nesse objeto acima é um vetor que indica em que grafo cada nó pertence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mais sobre datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Não é necessário usar a interface dataset, por exemplo, quando quiser criar dados sintéticos dinamicamente, sem salvá-los explicitamente no disco. Neste caso, simplesmente passe uma lista python regular contendo objetos Data e passe-os para o DataLoader:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "data_list = [Data(...), ..., Data(...)]\n",
    "loader = DataLoader(data_list, batch_size=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A biblioteca DeepSnap pode user útil para criar e trabalhar com datasets no Pytorch Geometric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/wsl/PHYSICALDRIVE2/Utfpr/TCC/TCC_graphs_study/.venv/lib/python3.11/site-packages/deepsnap/graph.py:522: UserWarning: Node related key is required.\n",
      "  warnings.warn(\"Node related key is required.\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import networkx as nx\n",
    "from deepsnap.graph import Graph\n",
    "from deepsnap.dataset import GraphDataset\n",
    "\n",
    "G = nx.complete_graph(100)\n",
    "H1 = Graph(G)\n",
    "H2 = H1.clone()\n",
    "H3 = H1.clone()\n",
    "H4 = H1.clone()\n",
    "H5 = H1.clone()\n",
    "H6 = H1.clone()\n",
    "dataset = GraphDataset(graphs=[H1, H2, H3, H4, H5, H6], task = 'graph')\n",
    "len(dataset)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separando em treino e teste com o deepSNAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GraphDataset(3)\n",
      "GraphDataset(1)\n"
     ]
    }
   ],
   "source": [
    "train, val, test = dataset.split(transductive=False, split_ratio=[0.8, 0.1, 0.1])\n",
    "print(train)\n",
    "print(val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Indutive vs transdutive \n",
    "'indutive' (para datasets com vários gráficos) divide o dataset por grafos.Conjuntos distintos de grafos são usados para treinamento, validação e teste, e os gráficos de teste nunca  são vistos durante o treinamento. Isso pode ser feito para tarefas em nível de nó, borda e gráfico. \n",
    "\n",
    "'transdutive', todos os gráficos são vistos durante o tempo de treinamento, mas os rótulos de determinados nós e arestas não são observados no treinamento e são usados para validação e teste. Isso se aplica a tarefas em nível de nó e aresta."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
