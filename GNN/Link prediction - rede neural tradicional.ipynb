{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "from torch_geometric.datasets import Planetoid\n",
    "import torch_geometric.transforms as T\n",
    "import torch.optim as optim\n",
    "from torch.nn import Sequential, ReLU, Linear\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparação do dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[2708, 1433], edge_index=[2, 8446], y=[2708], edge_label=[2110], edge_label_index=[2, 2110])\n",
      "tensor([1., 1., 1.,  ..., 0., 0., 0.])\n"
     ]
    }
   ],
   "source": [
    "dataset = Planetoid(root='/tmp/Cora', name='Cora')\n",
    "data = dataset[0]\n",
    "\n",
    "data.train_mask = data.val_mask = data.test_mask = None\n",
    "\n",
    "#Note o detalhe para add_negative_train_samples=True (adiciona exemplos de nós que não possuem arestas)\n",
    "transform = T.RandomLinkSplit(is_undirected=True, add_negative_train_samples=True)\n",
    "train_data, val_data, test_data = transform(data)\n",
    "train_data = train_data.to(device)\n",
    "val_data=val_data.to(device)\n",
    "test_data = test_data.to(device)\n",
    "print(test_data)\n",
    "\n",
    "print(train_data.edge_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[2708, 1433], edge_index=[2, 10556], y=[2708])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Nota:\n",
    "\n",
    "Aqui estamos usando um dataset pronto que usou a interface 'dataset'. Veja comentários no notebook de Pytorch Geometric sobre possibilidades alternativas para montar o dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definição do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Feedforward(torch.nn.Module):\n",
    "    \n",
    "        def __init__(self, input_size, hidden_size):\n",
    "            super(Feedforward, self).__init__()\n",
    "            \n",
    "            self.input_size = input_size\n",
    "            self.hidden_size  = hidden_size\n",
    "            \n",
    "            self.fc1 = torch.nn.Linear(self.input_size, self.hidden_size)\n",
    "            self.fc2 = torch.nn.Linear(self.hidden_size, self.hidden_size)\n",
    "            self.fc3 = torch.nn.Linear(self.hidden_size, self.hidden_size)\n",
    "            self.fc4 = torch.nn.Linear(self.hidden_size, 1)\n",
    "            \n",
    "            self.relu = torch.nn.ReLU()\n",
    "            self.out_act = nn.Sigmoid()\n",
    "            \n",
    "            \n",
    "        def forward(self, x):\n",
    "            output = self.fc1(x)\n",
    "            output = self.relu(output)\n",
    "            \n",
    "            output = self.fc2(output)\n",
    "            output = self.relu(output)\n",
    "            \n",
    "            output = self.fc3(output)\n",
    "            output = self.relu(output)\n",
    "            \n",
    "            output = self.fc4(output)\n",
    "            \n",
    "            output = self.out_act(output)\n",
    "\n",
    "            return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criando features que representam as arestas: soma das features dos nós"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2110\n",
      "torch.Size([2110, 1433])\n",
      "torch.Size([7392, 1433])\n"
     ]
    }
   ],
   "source": [
    "num_features = train_data.x.shape[1]\n",
    "\n",
    "## Gerando as features para o treino\n",
    "featuresEdges_treino = \"\"\n",
    "\n",
    "totalEdges_treino = train_data.edge_label_index.shape[1]\n",
    "\n",
    "for col in range(0,totalEdges_treino):\n",
    "    node1 = train_data.edge_label_index[0,col]\n",
    "    node2 = train_data.edge_label_index[1,col]\n",
    "    \n",
    "    vals1 = train_data.x[[node1,]]\n",
    "    vals1 = torch.reshape(vals1, (1, num_features))\n",
    "    \n",
    "    vals2 = train_data.x[[node2,]]\n",
    "    vals2 = torch.reshape(vals2, (1, num_features))\n",
    "    \n",
    "    if col == 0:\n",
    "        featuresEdges_treino = vals1+vals2\n",
    "        continue\n",
    "        \n",
    "    somado = vals1+vals2\n",
    "    \n",
    "    featuresEdges_treino =  torch.cat((featuresEdges_treino, somado), dim=0) \n",
    "\n",
    "\n",
    "##########################################################################################\n",
    "##Gerando as features para o teste\n",
    "featuresEdges_teste = \"\"\n",
    "\n",
    "totalEdges_teste = test_data.edge_label_index.shape[1]\n",
    "print(totalEdges_teste)\n",
    "for col in range(0,totalEdges_teste):\n",
    "\n",
    "    node1 = test_data.edge_label_index[0,col]\n",
    "    node2 = test_data.edge_label_index[1,col]\n",
    "    \n",
    "    vals1 = test_data.x[[node1,]]\n",
    "    vals1 = torch.reshape(vals1, (1, num_features))\n",
    "\n",
    "    vals2 = test_data.x[[node2,]]\n",
    "    vals2 = torch.reshape(vals2, (1, num_features))\n",
    "    \n",
    "    if col == 0:\n",
    "        featuresEdges_teste = vals1+vals2\n",
    "        continue\n",
    "        \n",
    "    somado = vals1+vals2\n",
    "    \n",
    "    featuresEdges_teste =  torch.cat((featuresEdges_teste, somado), dim=0) \n",
    "\n",
    "print(featuresEdges_teste.shape)\n",
    "print(featuresEdges_treino.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instância do modelo e outros parâmetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feedforward(\n",
      "  (fc1): Linear(in_features=1433, out_features=64, bias=True)\n",
      "  (fc2): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (fc3): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (fc4): Linear(in_features=64, out_features=1, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (out_act): Sigmoid()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "num_features = train_data.x.shape[1]\n",
    "hidden_channel = 64\n",
    "\n",
    "model = Feedforward(num_features, hidden_channel).to(device)\n",
    "print(model)\n",
    "criterion = torch.nn.BCELoss()\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treino e teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Teste - perda antes do treinamento 0.6932457685470581\n",
      "Epoch 0: perda treino: 0.6932457685470581\n",
      "Epoch 1: perda treino: 0.6886391043663025\n",
      "Epoch 2: perda treino: 0.6709862351417542\n",
      "Epoch 3: perda treino: 0.6469810009002686\n",
      "Epoch 4: perda treino: 0.6615766882896423\n",
      "Epoch 5: perda treino: 0.6035478115081787\n",
      "Epoch 6: perda treino: 0.6120639443397522\n",
      "Epoch 7: perda treino: 0.5741829872131348\n",
      "Epoch 8: perda treino: 0.5759062170982361\n",
      "Epoch 9: perda treino: 0.5338155031204224\n",
      "Epoch 10: perda treino: 0.5342048406600952\n",
      "Epoch 11: perda treino: 0.4896065890789032\n",
      "Epoch 12: perda treino: 0.4978921711444855\n",
      "Epoch 13: perda treino: 0.4497186541557312\n",
      "Epoch 14: perda treino: 0.4346380829811096\n",
      "Epoch 15: perda treino: 0.4019308388233185\n",
      "Epoch 16: perda treino: 0.36785611510276794\n",
      "Epoch 17: perda treino: 0.35138803720474243\n",
      "Epoch 18: perda treino: 0.29474809765815735\n",
      "Epoch 19: perda treino: 0.2807169556617737\n",
      "Epoch 20: perda treino: 0.2647995352745056\n",
      "Epoch 21: perda treino: 0.2083253562450409\n",
      "Epoch 22: perda treino: 0.1805925965309143\n",
      "Epoch 23: perda treino: 0.17522427439689636\n",
      "Epoch 24: perda treino: 0.13279938697814941\n",
      "Epoch 25: perda treino: 0.10478398203849792\n",
      "Epoch 26: perda treino: 0.1009274572134018\n",
      "Epoch 27: perda treino: 0.06708689779043198\n",
      "Epoch 28: perda treino: 0.05680147558450699\n",
      "Epoch 29: perda treino: 0.042540326714515686\n",
      "Epoch 30: perda treino: 0.0303311999887228\n",
      "Epoch 31: perda treino: 0.02362893335521221\n",
      "Epoch 32: perda treino: 0.019607074558734894\n",
      "Epoch 33: perda treino: 0.012243963778018951\n",
      "Epoch 34: perda treino: 0.013321087695658207\n",
      "Epoch 35: perda treino: 0.007447158917784691\n",
      "Epoch 36: perda treino: 0.0056657264940440655\n",
      "Epoch 37: perda treino: 0.005468111485242844\n",
      "Epoch 38: perda treino: 0.003630313090980053\n",
      "Epoch 39: perda treino: 0.0024715419858694077\n",
      "Epoch 40: perda treino: 0.00213819881901145\n",
      "Epoch 41: perda treino: 0.0017056772485375404\n",
      "Epoch 42: perda treino: 0.0011484500719234347\n",
      "Epoch 43: perda treino: 0.0007812374387867749\n",
      "Epoch 44: perda treino: 0.0006605158559978008\n",
      "Epoch 45: perda treino: 0.0006215575849637389\n",
      "Epoch 46: perda treino: 0.0005051124608144164\n",
      "Epoch 47: perda treino: 0.00037530172266997397\n",
      "Epoch 48: perda treino: 0.00028991608996875584\n",
      "Epoch 49: perda treino: 0.00023780466290190816\n",
      "Epoch 50: perda treino: 0.00020901528478134423\n",
      "Epoch 51: perda treino: 0.00019644589337985963\n",
      "Epoch 52: perda treino: 0.00018418653053231537\n",
      "Epoch 53: perda treino: 0.00016075014718808234\n",
      "Epoch 54: perda treino: 0.00013340225268620998\n",
      "Epoch 55: perda treino: 0.00011111397907370701\n",
      "Epoch 56: perda treino: 9.546021465212107e-05\n",
      "Epoch 57: perda treino: 8.422611426794901e-05\n",
      "Epoch 58: perda treino: 7.584047853015363e-05\n",
      "Epoch 59: perda treino: 6.93203037371859e-05\n",
      "Epoch 60: perda treino: 6.406624743249267e-05\n",
      "Epoch 61: perda treino: 5.962643990642391e-05\n",
      "Epoch 62: perda treino: 5.5715267080813646e-05\n",
      "Epoch 63: perda treino: 5.2308041631476954e-05\n",
      "Epoch 64: perda treino: 4.917624028166756e-05\n",
      "Epoch 65: perda treino: 4.622834239853546e-05\n",
      "Epoch 66: perda treino: 4.340334635344334e-05\n",
      "Epoch 67: perda treino: 4.072458978043869e-05\n",
      "Epoch 68: perda treino: 3.8253892853390425e-05\n",
      "Epoch 69: perda treino: 3.6018558603245765e-05\n",
      "Epoch 70: perda treino: 3.402213769732043e-05\n",
      "Epoch 71: perda treino: 3.225002365070395e-05\n",
      "Epoch 72: perda treino: 3.067972284043208e-05\n",
      "Epoch 73: perda treino: 2.9284783522598445e-05\n",
      "Epoch 74: perda treino: 2.8043474230798893e-05\n",
      "Epoch 75: perda treino: 2.693083843041677e-05\n",
      "Epoch 76: perda treino: 2.5930503397830762e-05\n",
      "Epoch 77: perda treino: 2.502013012417592e-05\n",
      "Epoch 78: perda treino: 2.4164422939065844e-05\n",
      "Epoch 79: perda treino: 2.3343438442680053e-05\n",
      "Epoch 80: perda treino: 2.254485480079893e-05\n",
      "Epoch 81: perda treino: 2.176323141611647e-05\n",
      "Epoch 82: perda treino: 2.0993036741856486e-05\n",
      "Epoch 83: perda treino: 2.0230454538250342e-05\n",
      "Epoch 84: perda treino: 1.947699456650298e-05\n",
      "Epoch 85: perda treino: 1.8731912859948352e-05\n",
      "Epoch 86: perda treino: 1.799764868337661e-05\n",
      "Epoch 87: perda treino: 1.7278283849009313e-05\n",
      "Epoch 88: perda treino: 1.6573912944295444e-05\n",
      "Epoch 89: perda treino: 1.58883813128341e-05\n",
      "Epoch 90: perda treino: 1.5225436072796583e-05\n",
      "Epoch 91: perda treino: 1.4588130397896748e-05\n",
      "Epoch 92: perda treino: 1.3978708011563867e-05\n",
      "Epoch 93: perda treino: 1.339851769444067e-05\n",
      "Epoch 94: perda treino: 1.2846790014009457e-05\n",
      "Epoch 95: perda treino: 1.2326733667578083e-05\n",
      "Epoch 96: perda treino: 1.1836307749035768e-05\n",
      "Epoch 97: perda treino: 1.1376042493793648e-05\n",
      "Epoch 98: perda treino: 1.0944575478788465e-05\n",
      "Epoch 99: perda treino: 1.0540200491959695e-05\n",
      "Epoch 100: perda treino: 1.016124224406667e-05\n",
      "Epoch 101: perda treino: 9.806338312046137e-06\n",
      "Epoch 102: perda treino: 9.47416901908582e-06\n",
      "Epoch 103: perda treino: 9.163970389636233e-06\n",
      "Epoch 104: perda treino: 8.872921171132475e-06\n",
      "Epoch 105: perda treino: 8.600283763371408e-06\n",
      "Epoch 106: perda treino: 8.34526235848898e-06\n",
      "Epoch 107: perda treino: 8.10523397376528e-06\n",
      "Epoch 108: perda treino: 7.880119483161252e-06\n",
      "Epoch 109: perda treino: 7.668923899473157e-06\n",
      "Epoch 110: perda treino: 7.4697722993732896e-06\n",
      "Epoch 111: perda treino: 7.282469141500769e-06\n",
      "Epoch 112: perda treino: 7.105674285412533e-06\n",
      "Epoch 113: perda treino: 6.9380903369165026e-06\n",
      "Epoch 114: perda treino: 6.779837804060662e-06\n",
      "Epoch 115: perda treino: 6.629497875110246e-06\n",
      "Epoch 116: perda treino: 6.487312475655926e-06\n",
      "Epoch 117: perda treino: 6.352175205392996e-06\n",
      "Epoch 118: perda treino: 6.223725449672202e-06\n",
      "Epoch 119: perda treino: 6.100839982536854e-06\n",
      "Epoch 120: perda treino: 5.984263225400355e-06\n",
      "Epoch 121: perda treino: 5.872935162187787e-06\n",
      "Epoch 122: perda treino: 5.76717366129742e-06\n",
      "Epoch 123: perda treino: 5.666082870448008e-06\n",
      "Epoch 124: perda treino: 5.56890290681622e-06\n",
      "Epoch 125: perda treino: 5.475756097439444e-06\n",
      "Epoch 126: perda treino: 5.386666089179926e-06\n",
      "Epoch 127: perda treino: 5.301382770994678e-06\n",
      "Epoch 128: perda treino: 5.2195287025824655e-06\n",
      "Epoch 129: perda treino: 5.140754637977807e-06\n",
      "Epoch 130: perda treino: 5.064699507784098e-06\n",
      "Epoch 131: perda treino: 4.992185040464392e-06\n",
      "Epoch 132: perda treino: 4.921638264931971e-06\n",
      "Epoch 133: perda treino: 4.854156486544525e-06\n",
      "Epoch 134: perda treino: 4.7888047447486315e-06\n",
      "Epoch 135: perda treino: 4.725477538158884e-06\n",
      "Epoch 136: perda treino: 4.664125754061388e-06\n",
      "Epoch 137: perda treino: 4.605323283612961e-06\n",
      "Epoch 138: perda treino: 4.548133802018128e-06\n",
      "Epoch 139: perda treino: 4.492630978347734e-06\n",
      "Epoch 140: perda treino: 4.439087206264958e-06\n",
      "Epoch 141: perda treino: 4.386778073239839e-06\n",
      "Epoch 142: perda treino: 4.336130587034859e-06\n",
      "Epoch 143: perda treino: 4.286999228497734e-06\n",
      "Epoch 144: perda treino: 4.239392637828132e-06\n",
      "Epoch 145: perda treino: 4.192882897768868e-06\n",
      "Epoch 146: perda treino: 4.147631443629507e-06\n",
      "Epoch 147: perda treino: 4.10393658967223e-06\n",
      "Epoch 148: perda treino: 4.060806531924754e-06\n",
      "Epoch 149: perda treino: 4.0188465391111095e-06\n",
      "Epoch 150: perda treino: 3.978103450208437e-06\n",
      "Epoch 151: perda treino: 3.938192094210535e-06\n",
      "Epoch 152: perda treino: 3.899619514413644e-06\n",
      "Epoch 153: perda treino: 3.861538971250411e-06\n",
      "Epoch 154: perda treino: 3.824450232059462e-06\n",
      "Epoch 155: perda treino: 3.788386493397411e-06\n",
      "Epoch 156: perda treino: 3.752637212528498e-06\n",
      "Epoch 157: perda treino: 3.7179522678343346e-06\n",
      "Epoch 158: perda treino: 3.6838162031926913e-06\n",
      "Epoch 159: perda treino: 3.650906137409038e-06\n",
      "Epoch 160: perda treino: 3.6181736504659057e-06\n",
      "Epoch 161: perda treino: 3.5861264677805593e-06\n",
      "Epoch 162: perda treino: 3.554797558535938e-06\n",
      "Epoch 163: perda treino: 3.52412166648719e-06\n",
      "Epoch 164: perda treino: 3.494051270536147e-06\n",
      "Epoch 165: perda treino: 3.4643273920664797e-06\n",
      "Epoch 166: perda treino: 3.4352572129137116e-06\n",
      "Epoch 167: perda treino: 3.4068236800521845e-06\n",
      "Epoch 168: perda treino: 3.3786568565119524e-06\n",
      "Epoch 169: perda treino: 3.3511591936985496e-06\n",
      "Epoch 170: perda treino: 3.3242829431401333e-06\n",
      "Epoch 171: perda treino: 3.2972936878650216e-06\n",
      "Epoch 172: perda treino: 3.271062723797513e-06\n",
      "Epoch 173: perda treino: 3.245146444896818e-06\n",
      "Epoch 174: perda treino: 3.2199234283325495e-06\n",
      "Epoch 175: perda treino: 3.1952890822140034e-06\n",
      "Epoch 176: perda treino: 3.170744321323582e-06\n",
      "Epoch 177: perda treino: 3.146811877741129e-06\n",
      "Epoch 178: perda treino: 3.1227914405462798e-06\n",
      "Epoch 179: perda treino: 3.0993758173281094e-06\n",
      "Epoch 180: perda treino: 3.076354687436833e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 181: perda treino: 3.053592308788211e-06\n",
      "Epoch 182: perda treino: 3.0311769023683155e-06\n",
      "Epoch 183: perda treino: 3.0091325697867433e-06\n",
      "Epoch 184: perda treino: 2.9873942821723176e-06\n",
      "Epoch 185: perda treino: 2.965970907098381e-06\n",
      "Epoch 186: perda treino: 2.944878360722214e-06\n",
      "Epoch 187: perda treino: 2.9240518415463157e-06\n",
      "Epoch 188: perda treino: 2.9036527848802507e-06\n",
      "Epoch 189: perda treino: 2.883310344259371e-06\n",
      "Epoch 190: perda treino: 2.863500185412704e-06\n",
      "Epoch 191: perda treino: 2.8438030312827323e-06\n",
      "Epoch 192: perda treino: 2.8242109237908153e-06\n",
      "Epoch 193: perda treino: 2.8049814773112303e-06\n",
      "Epoch 194: perda treino: 2.786147433653241e-06\n",
      "Epoch 195: perda treino: 2.7671762836689595e-06\n",
      "Epoch 196: perda treino: 2.7486084945849143e-06\n",
      "Epoch 197: perda treino: 2.7304681680107024e-06\n",
      "Epoch 198: perda treino: 2.712513833103003e-06\n",
      "Epoch 199: perda treino: 2.6948493996314937e-06\n",
      "Epoch 200: perda treino: 2.6770799195219297e-06\n",
      "Epoch 201: perda treino: 2.659924120962387e-06\n",
      "Epoch 202: perda treino: 2.642654862938798e-06\n",
      "Epoch 203: perda treino: 2.6258376237819903e-06\n",
      "Epoch 204: perda treino: 2.6090845040016575e-06\n",
      "Epoch 205: perda treino: 2.592468945294968e-06\n",
      "Epoch 206: perda treino: 2.576191945991013e-06\n",
      "Epoch 207: perda treino: 2.5602053028705996e-06\n",
      "Epoch 208: perda treino: 2.5440338049520506e-06\n",
      "Epoch 209: perda treino: 2.528643790356e-06\n",
      "Epoch 210: perda treino: 2.512907258278574e-06\n",
      "Epoch 211: perda treino: 2.497558170944103e-06\n",
      "Epoch 212: perda treino: 2.4823457351885736e-06\n",
      "Epoch 213: perda treino: 2.4673033749422757e-06\n",
      "Epoch 214: perda treino: 2.452454054946429e-06\n",
      "Epoch 215: perda treino: 2.4376940928050317e-06\n",
      "Epoch 216: perda treino: 2.423094656478497e-06\n",
      "Epoch 217: perda treino: 2.408672798992484e-06\n",
      "Epoch 218: perda treino: 2.394267539784778e-06\n",
      "Epoch 219: perda treino: 2.380152636760613e-06\n",
      "Epoch 220: perda treino: 2.3662066723773023e-06\n",
      "Epoch 221: perda treino: 2.3523257368651684e-06\n",
      "Epoch 222: perda treino: 2.338831791348639e-06\n",
      "Epoch 223: perda treino: 2.3252973733178806e-06\n",
      "Epoch 224: perda treino: 2.312069227627944e-06\n",
      "Epoch 225: perda treino: 2.2986885142017854e-06\n",
      "Epoch 226: perda treino: 2.2855656425235793e-06\n",
      "Epoch 227: perda treino: 2.272418669235776e-06\n",
      "Epoch 228: perda treino: 2.2595700102101546e-06\n",
      "Epoch 229: perda treino: 2.2467856979346834e-06\n",
      "Epoch 230: perda treino: 2.234187377325725e-06\n",
      "Epoch 231: perda treino: 2.2216693196241977e-06\n",
      "Epoch 232: perda treino: 2.209191961810575e-06\n",
      "Epoch 233: perda treino: 2.197214143961901e-06\n",
      "Epoch 234: perda treino: 2.185027142331819e-06\n",
      "Epoch 235: perda treino: 2.1729526906710817e-06\n",
      "Epoch 236: perda treino: 2.1612092950817896e-06\n",
      "Epoch 237: perda treino: 2.149570264009526e-06\n",
      "Epoch 238: perda treino: 2.1379398731369292e-06\n",
      "Epoch 239: perda treino: 2.1263495000312105e-06\n",
      "Epoch 240: perda treino: 2.1147836832824396e-06\n",
      "Epoch 241: perda treino: 2.1036773887317395e-06\n",
      "Epoch 242: perda treino: 2.092692056976375e-06\n",
      "Epoch 243: perda treino: 2.081618049487588e-06\n",
      "Epoch 244: perda treino: 2.070519485641853e-06\n",
      "Epoch 245: perda treino: 2.0597360617102822e-06\n",
      "Epoch 246: perda treino: 2.0489121652644826e-06\n",
      "Epoch 247: perda treino: 2.038354068645276e-06\n",
      "Epoch 248: perda treino: 2.027756181632867e-06\n",
      "Epoch 249: perda treino: 2.0172062704659766e-06\n",
      "Epoch 250: perda treino: 2.0067693640157813e-06\n",
      "Epoch 251: perda treino: 1.9965102637797827e-06\n",
      "Epoch 252: perda treino: 1.9862995941366535e-06\n",
      "Epoch 253: perda treino: 1.976209432541509e-06\n",
      "Epoch 254: perda treino: 1.966312765944167e-06\n",
      "Epoch 255: perda treino: 1.956271489689243e-06\n",
      "Epoch 256: perda treino: 1.946536485775141e-06\n",
      "Epoch 257: perda treino: 1.9366241303941933e-06\n",
      "Epoch 258: perda treino: 1.9270503344159806e-06\n",
      "Epoch 259: perda treino: 1.917460622280487e-06\n",
      "Epoch 260: perda treino: 1.9079916455666535e-06\n",
      "Epoch 261: perda treino: 1.8984342204930726e-06\n",
      "Epoch 262: perda treino: 1.8893362039307249e-06\n",
      "Epoch 263: perda treino: 1.8800126326823374e-06\n",
      "Epoch 264: perda treino: 1.8707373783399817e-06\n",
      "Epoch 265: perda treino: 1.8613251313581713e-06\n",
      "Epoch 266: perda treino: 1.8524208371673012e-06\n",
      "Epoch 267: perda treino: 1.8434118373988895e-06\n",
      "Epoch 268: perda treino: 1.8346205479247146e-06\n",
      "Epoch 269: perda treino: 1.8258292584505398e-06\n",
      "Epoch 270: perda treino: 1.8169976101489738e-06\n",
      "Epoch 271: perda treino: 1.8083514987665694e-06\n",
      "Epoch 272: perda treino: 1.7997377881329157e-06\n",
      "Epoch 273: perda treino: 1.7912692555910326e-06\n",
      "Epoch 274: perda treino: 1.782897243174375e-06\n",
      "Epoch 275: perda treino: 1.7743642501955037e-06\n",
      "Epoch 276: perda treino: 1.7661941456026398e-06\n",
      "Epoch 277: perda treino: 1.7579511677467963e-06\n",
      "Epoch 278: perda treino: 1.7498214219813235e-06\n",
      "Epoch 279: perda treino: 1.7416510900147841e-06\n",
      "Epoch 280: perda treino: 1.7335859183731372e-06\n",
      "Epoch 281: perda treino: 1.7255769080293248e-06\n",
      "Epoch 282: perda treino: 1.717632585496176e-06\n",
      "Epoch 283: perda treino: 1.7096158444473986e-06\n",
      "Epoch 284: perda treino: 1.7018085145537043e-06\n",
      "Epoch 285: perda treino: 1.6942757383731077e-06\n",
      "Epoch 286: perda treino: 1.6864282770256978e-06\n",
      "Epoch 287: perda treino: 1.678709736552264e-06\n",
      "Epoch 288: perda treino: 1.6713541981516755e-06\n",
      "Epoch 289: perda treino: 1.6637566204735776e-06\n",
      "Epoch 290: perda treino: 1.6562478322157403e-06\n",
      "Epoch 291: perda treino: 1.648755414862535e-06\n",
      "Epoch 292: perda treino: 1.6412789136666106e-06\n",
      "Epoch 293: perda treino: 1.633963847780251e-06\n",
      "Epoch 294: perda treino: 1.6265277054117178e-06\n",
      "Epoch 295: perda treino: 1.6193496321648126e-06\n",
      "Epoch 296: perda treino: 1.6122603483381681e-06\n",
      "Epoch 297: perda treino: 1.6052114233389148e-06\n",
      "Epoch 298: perda treino: 1.5980333500920096e-06\n",
      "Epoch 299: perda treino: 1.5909682815617998e-06\n",
      "Epoch 300: perda treino: 1.5840162177482853e-06\n",
      "Epoch 301: perda treino: 1.5772898223076481e-06\n",
      "Epoch 302: perda treino: 1.5705472833360545e-06\n",
      "Epoch 303: perda treino: 1.563675709803647e-06\n",
      "Epoch 304: perda treino: 1.556828351567674e-06\n",
      "Epoch 305: perda treino: 1.5502070027650916e-06\n",
      "Epoch 306: perda treino: 1.5434968645422487e-06\n",
      "Epoch 307: perda treino: 1.536996137474489e-06\n",
      "Epoch 308: perda treino: 1.5303829741242225e-06\n",
      "Epoch 309: perda treino: 1.5238258583849529e-06\n",
      "Epoch 310: perda treino: 1.5171154927884345e-06\n",
      "Epoch 311: perda treino: 1.5106797945918515e-06\n",
      "Epoch 312: perda treino: 1.5043565326777752e-06\n",
      "Epoch 313: perda treino: 1.4979688103267108e-06\n",
      "Epoch 314: perda treino: 1.4916619193172664e-06\n",
      "Epoch 315: perda treino: 1.4852904541839962e-06\n",
      "Epoch 316: perda treino: 1.4790319937674212e-06\n",
      "Epoch 317: perda treino: 1.4726283552590758e-06\n",
      "Epoch 318: perda treino: 1.466611593059497e-06\n",
      "Epoch 319: perda treino: 1.4603368754251278e-06\n",
      "Epoch 320: perda treino: 1.454239622944442e-06\n",
      "Epoch 321: perda treino: 1.4484809298664914e-06\n",
      "Epoch 322: perda treino: 1.4423758329940028e-06\n",
      "Epoch 323: perda treino: 1.4362542515300447e-06\n",
      "Epoch 324: perda treino: 1.4302620456874138e-06\n",
      "Epoch 325: perda treino: 1.4244308204069966e-06\n",
      "Epoch 326: perda treino: 1.4184465726430062e-06\n",
      "Epoch 327: perda treino: 1.4127042504696874e-06\n",
      "Epoch 328: perda treino: 1.406840851814195e-06\n",
      "Epoch 329: perda treino: 1.4010097402206156e-06\n",
      "Epoch 330: perda treino: 1.3952351309853839e-06\n",
      "Epoch 331: perda treino: 1.3896137716074008e-06\n",
      "Epoch 332: perda treino: 1.3837425285601057e-06\n",
      "Epoch 333: perda treino: 1.3780886547465343e-06\n",
      "Epoch 334: perda treino: 1.3726852330364636e-06\n",
      "Epoch 335: perda treino: 1.36716869292286e-06\n",
      "Epoch 336: perda treino: 1.3617328704640386e-06\n",
      "Epoch 337: perda treino: 1.3563050060838577e-06\n",
      "Epoch 338: perda treino: 1.3507241192201036e-06\n",
      "Epoch 339: perda treino: 1.3452398661684128e-06\n",
      "Epoch 340: perda treino: 1.3400621128312196e-06\n",
      "Epoch 341: perda treino: 1.334642320216517e-06\n",
      "Epoch 342: perda treino: 1.329311317022075e-06\n",
      "Epoch 343: perda treino: 1.323980313827633e-06\n",
      "Epoch 344: perda treino: 1.3186736396164633e-06\n",
      "Epoch 345: perda treino: 1.3133669654052937e-06\n",
      "Epoch 346: perda treino: 1.308173068537144e-06\n",
      "Epoch 347: perda treino: 1.3032774859311758e-06\n",
      "Epoch 348: perda treino: 1.2981239478904172e-06\n",
      "Epoch 349: perda treino: 1.2931155879414291e-06\n",
      "Epoch 350: perda treino: 1.2880105941803777e-06\n",
      "Epoch 351: perda treino: 1.282945731873042e-06\n",
      "Epoch 352: perda treino: 1.2778890550180222e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 353: perda treino: 1.2729451555060223e-06\n",
      "Epoch 354: perda treino: 1.2681143743975554e-06\n",
      "Epoch 355: perda treino: 1.263097942683089e-06\n",
      "Epoch 356: perda treino: 1.2582993349496974e-06\n",
      "Epoch 357: perda treino: 1.2535248288259027e-06\n",
      "Epoch 358: perda treino: 1.248798866981815e-06\n",
      "Epoch 359: perda treino: 1.244064492311736e-06\n",
      "Epoch 360: perda treino: 1.239330572389008e-06\n",
      "Epoch 361: perda treino: 1.2347255733402562e-06\n",
      "Epoch 362: perda treino: 1.2299833542783745e-06\n",
      "Epoch 363: perda treino: 1.225297751261678e-06\n",
      "Epoch 364: perda treino: 1.2208056432427838e-06\n",
      "Epoch 365: perda treino: 1.2161278846178902e-06\n",
      "Epoch 366: perda treino: 1.2116922789573437e-06\n",
      "Epoch 367: perda treino: 1.2071677701896988e-06\n",
      "Epoch 368: perda treino: 1.2026434887957294e-06\n",
      "Epoch 369: perda treino: 1.1981270517935627e-06\n",
      "Epoch 370: perda treino: 1.1936027703995933e-06\n",
      "Epoch 371: perda treino: 1.189167051052209e-06\n",
      "Epoch 372: perda treino: 1.1848040912809665e-06\n",
      "Epoch 373: perda treino: 1.1803927009168547e-06\n",
      "Epoch 374: perda treino: 1.176069872599328e-06\n",
      "Epoch 375: perda treino: 1.1717955885615083e-06\n",
      "Epoch 376: perda treino: 1.1674082998069935e-06\n",
      "Epoch 377: perda treino: 1.1630936569417827e-06\n",
      "Epoch 378: perda treino: 1.1588515462790383e-06\n",
      "Epoch 379: perda treino: 1.1546095493031316e-06\n",
      "Epoch 380: perda treino: 1.1504320127642131e-06\n",
      "Epoch 381: perda treino: 1.1461899021014688e-06\n",
      "Epoch 382: perda treino: 1.142084784078179e-06\n",
      "Epoch 383: perda treino: 1.138092784458422e-06\n",
      "Epoch 384: perda treino: 1.1339958518874482e-06\n",
      "Epoch 385: perda treino: 1.1298828894723556e-06\n",
      "Epoch 386: perda treino: 1.1259955954301404e-06\n",
      "Epoch 387: perda treino: 1.121858417718613e-06\n",
      "Epoch 388: perda treino: 1.1176890666320105e-06\n",
      "Epoch 389: perda treino: 1.1137615274492418e-06\n",
      "Epoch 390: perda treino: 1.1098178447355167e-06\n",
      "Epoch 391: perda treino: 1.1058339168812381e-06\n",
      "Epoch 392: perda treino: 1.1019870953532518e-06\n",
      "Epoch 393: perda treino: 1.0981642617480247e-06\n",
      "Epoch 394: perda treino: 1.094236722565256e-06\n",
      "Epoch 395: perda treino: 1.0903496558967163e-06\n",
      "Epoch 396: perda treino: 1.0865270496651647e-06\n",
      "Epoch 397: perda treino: 1.082567223420483e-06\n",
      "Epoch 398: perda treino: 1.0789461839522119e-06\n",
      "Epoch 399: perda treino: 1.075171894626692e-06\n",
      "Epoch 400: perda treino: 1.0714378504417255e-06\n",
      "Epoch 401: perda treino: 1.067760535988782e-06\n",
      "Epoch 402: perda treino: 1.0640345635692938e-06\n",
      "Epoch 403: perda treino: 1.0604215958665009e-06\n",
      "Epoch 404: perda treino: 1.0567764547886327e-06\n",
      "Epoch 405: perda treino: 1.0532037322263932e-06\n",
      "Epoch 406: perda treino: 1.0495505193830468e-06\n",
      "Epoch 407: perda treino: 1.0458730912432657e-06\n",
      "Epoch 408: perda treino: 1.0422843388369074e-06\n",
      "Epoch 409: perda treino: 1.0386148687757668e-06\n",
      "Epoch 410: perda treino: 1.0352197250540485e-06\n",
      "Epoch 411: perda treino: 1.0318003660358954e-06\n",
      "Epoch 412: perda treino: 1.0282277571604936e-06\n",
      "Epoch 413: perda treino: 1.024848643282894e-06\n",
      "Epoch 414: perda treino: 1.0214372423433815e-06\n",
      "Epoch 415: perda treino: 1.0178405318583827e-06\n",
      "Epoch 416: perda treino: 1.014453346215305e-06\n",
      "Epoch 417: perda treino: 1.011163021757966e-06\n",
      "Epoch 418: perda treino: 1.0077275192088564e-06\n",
      "Epoch 419: perda treino: 1.0043080465038656e-06\n",
      "Epoch 420: perda treino: 1.0010903679358307e-06\n",
      "Epoch 421: perda treino: 9.97832216853567e-07\n",
      "Epoch 422: perda treino: 9.944853900378803e-07\n",
      "Epoch 423: perda treino: 9.911626648317906e-07\n",
      "Epoch 424: perda treino: 9.87735347734997e-07\n",
      "Epoch 425: perda treino: 9.844933401836897e-07\n",
      "Epoch 426: perda treino: 9.811626568989595e-07\n",
      "Epoch 427: perda treino: 9.778642606761423e-07\n",
      "Epoch 428: perda treino: 9.746061095938785e-07\n",
      "Epoch 429: perda treino: 9.71146505435172e-07\n",
      "Epoch 430: perda treino: 9.679931736172875e-07\n",
      "Epoch 431: perda treino: 9.648236982684466e-07\n",
      "Epoch 432: perda treino: 9.615010867491947e-07\n",
      "Epoch 433: perda treino: 9.58291479946638e-07\n",
      "Epoch 434: perda treino: 9.550333288643742e-07\n",
      "Epoch 435: perda treino: 9.518720389678492e-07\n",
      "Epoch 436: perda treino: 9.48734964367759e-07\n",
      "Epoch 437: perda treino: 9.456138059249497e-07\n",
      "Epoch 438: perda treino: 9.42460587793903e-07\n",
      "Epoch 439: perda treino: 9.394524909112079e-07\n",
      "Epoch 440: perda treino: 9.362750574837264e-07\n",
      "Epoch 441: perda treino: 9.331944852419838e-07\n",
      "Epoch 442: perda treino: 9.300733836425934e-07\n",
      "Epoch 443: perda treino: 9.270733585253765e-07\n",
      "Epoch 444: perda treino: 9.241459792974638e-07\n",
      "Epoch 445: perda treino: 9.211539122588874e-07\n",
      "Epoch 446: perda treino: 9.180975553135795e-07\n",
      "Epoch 447: perda treino: 9.152104780696391e-07\n",
      "Epoch 448: perda treino: 9.124360644818807e-07\n",
      "Epoch 449: perda treino: 9.095329005504027e-07\n",
      "Epoch 450: perda treino: 9.064361279342847e-07\n",
      "Epoch 451: perda treino: 9.036054962052731e-07\n",
      "Epoch 452: perda treino: 9.007424637275108e-07\n",
      "Epoch 453: perda treino: 8.97823269951914e-07\n",
      "Epoch 454: perda treino: 8.949602943175705e-07\n",
      "Epoch 455: perda treino: 8.920328582462389e-07\n",
      "Epoch 456: perda treino: 8.892747587196936e-07\n",
      "Epoch 457: perda treino: 8.863473794917809e-07\n",
      "Epoch 458: perda treino: 8.835328344503068e-07\n",
      "Epoch 459: perda treino: 8.807506333141646e-07\n",
      "Epoch 460: perda treino: 8.778716278357024e-07\n",
      "Epoch 461: perda treino: 8.749764219828648e-07\n",
      "Epoch 462: perda treino: 8.722828965801455e-07\n",
      "Epoch 463: perda treino: 8.694523785379715e-07\n",
      "Epoch 464: perda treino: 8.668071700412838e-07\n",
      "Epoch 465: perda treino: 8.640571422802168e-07\n",
      "Epoch 466: perda treino: 8.613716886429756e-07\n",
      "Epoch 467: perda treino: 8.587668389736791e-07\n",
      "Epoch 468: perda treino: 8.559765092286398e-07\n",
      "Epoch 469: perda treino: 8.533475579497463e-07\n",
      "Epoch 470: perda treino: 8.50750780045928e-07\n",
      "Epoch 471: perda treino: 8.480895985485404e-07\n",
      "Epoch 472: perda treino: 8.45420174755418e-07\n",
      "Epoch 473: perda treino: 8.427186912740581e-07\n",
      "Epoch 474: perda treino: 8.402186608691409e-07\n",
      "Epoch 475: perda treino: 8.376219966521603e-07\n",
      "Epoch 476: perda treino: 8.350413054358796e-07\n",
      "Epoch 477: perda treino: 8.325574754053378e-07\n",
      "Epoch 478: perda treino: 8.299203955175471e-07\n",
      "Epoch 479: perda treino: 8.274687957054994e-07\n",
      "Epoch 480: perda treino: 8.249043617070129e-07\n",
      "Epoch 481: perda treino: 8.223317990996293e-07\n",
      "Epoch 482: perda treino: 8.198318255381309e-07\n",
      "Epoch 483: perda treino: 8.174448566933279e-07\n",
      "Epoch 484: perda treino: 8.148884376169008e-07\n",
      "Epoch 485: perda treino: 8.124691248667659e-07\n",
      "Epoch 486: perda treino: 8.100740274130658e-07\n",
      "Epoch 487: perda treino: 8.076062272266427e-07\n",
      "Epoch 488: perda treino: 8.051950430854049e-07\n",
      "Epoch 489: perda treino: 8.028240472413017e-07\n",
      "Epoch 490: perda treino: 8.003644893506134e-07\n",
      "Epoch 491: perda treino: 7.980984264577273e-07\n",
      "Epoch 492: perda treino: 7.955903811307508e-07\n",
      "Epoch 493: perda treino: 7.93114679709106e-07\n",
      "Epoch 494: perda treino: 7.908486168162199e-07\n",
      "Epoch 495: perda treino: 7.884291903792473e-07\n",
      "Epoch 496: perda treino: 7.860744517529383e-07\n",
      "Epoch 497: perda treino: 7.838325473130681e-07\n",
      "Epoch 498: perda treino: 7.814938953742967e-07\n",
      "Epoch 499: perda treino: 7.791795155753789e-07\n",
      "Epoch 500: perda treino: 7.768085765746946e-07\n",
      "Epoch 501: perda treino: 7.74526370150852e-07\n",
      "Epoch 502: perda treino: 7.723168096163135e-07\n",
      "Epoch 503: perda treino: 7.699378556935699e-07\n",
      "Epoch 504: perda treino: 7.67808899126976e-07\n",
      "Epoch 505: perda treino: 7.655669378436869e-07\n",
      "Epoch 506: perda treino: 7.633976792931207e-07\n",
      "Epoch 507: perda treino: 7.612445074300922e-07\n",
      "Epoch 508: perda treino: 7.590268182866566e-07\n",
      "Epoch 509: perda treino: 7.56817314595537e-07\n",
      "Epoch 510: perda treino: 7.546883011855243e-07\n",
      "Epoch 511: perda treino: 7.525270575570175e-07\n",
      "Epoch 512: perda treino: 7.503173264922225e-07\n",
      "Epoch 513: perda treino: 7.481642683160317e-07\n",
      "Epoch 514: perda treino: 7.460515121238132e-07\n",
      "Epoch 515: perda treino: 7.439789442287292e-07\n",
      "Epoch 516: perda treino: 7.417773986162501e-07\n",
      "Epoch 517: perda treino: 7.396888008770475e-07\n",
      "Epoch 518: perda treino: 7.374953270300466e-07\n",
      "Epoch 519: perda treino: 7.354793183367292e-07\n",
      "Epoch 520: perda treino: 7.334310225814988e-07\n",
      "Epoch 521: perda treino: 7.313826131394308e-07\n",
      "Epoch 522: perda treino: 7.29390819742548e-07\n",
      "Epoch 523: perda treino: 7.27221504348563e-07\n",
      "Epoch 524: perda treino: 7.251732085933327e-07\n",
      "Epoch 525: perda treino: 7.233264796013827e-07\n",
      "Epoch 526: perda treino: 7.213265575956029e-07\n",
      "Epoch 527: perda treino: 7.19165370810515e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 528: perda treino: 7.170444860093994e-07\n",
      "Epoch 529: perda treino: 7.151977570174495e-07\n",
      "Epoch 530: perda treino: 7.132382506824797e-07\n",
      "Epoch 531: perda treino: 7.112785738172533e-07\n",
      "Epoch 532: perda treino: 7.093754561537935e-07\n",
      "Epoch 533: perda treino: 7.073835490700731e-07\n",
      "Epoch 534: perda treino: 7.054320576571627e-07\n",
      "Epoch 535: perda treino: 7.034482791823393e-07\n",
      "Epoch 536: perda treino: 7.015370329099824e-07\n",
      "Epoch 537: perda treino: 6.997145192144671e-07\n",
      "Epoch 538: perda treino: 6.978114015510073e-07\n",
      "Epoch 539: perda treino: 6.959405709494604e-07\n",
      "Epoch 540: perda treino: 6.941341439414828e-07\n",
      "Epoch 541: perda treino: 6.922230113559635e-07\n",
      "Epoch 542: perda treino: 6.903359803800413e-07\n",
      "Epoch 543: perda treino: 6.884086474201467e-07\n",
      "Epoch 544: perda treino: 6.865539035061374e-07\n",
      "Epoch 545: perda treino: 6.846749442956934e-07\n",
      "Epoch 546: perda treino: 6.82973393395514e-07\n",
      "Epoch 547: perda treino: 6.809492560932995e-07\n",
      "Epoch 548: perda treino: 6.792396902710607e-07\n",
      "Epoch 549: perda treino: 6.774494636374584e-07\n",
      "Epoch 550: perda treino: 6.756188213330461e-07\n",
      "Epoch 551: perda treino: 6.738932256666885e-07\n",
      "Epoch 552: perda treino: 6.720867986587109e-07\n",
      "Epoch 553: perda treino: 6.703771759930532e-07\n",
      "Epoch 554: perda treino: 6.68530560687941e-07\n",
      "Epoch 555: perda treino: 6.666758167739317e-07\n",
      "Epoch 556: perda treino: 6.649904094047088e-07\n",
      "Epoch 557: perda treino: 6.632243412241223e-07\n",
      "Epoch 558: perda treino: 6.615228471673618e-07\n",
      "Epoch 559: perda treino: 6.596438879569178e-07\n",
      "Epoch 560: perda treino: 6.579101068382442e-07\n",
      "Epoch 561: perda treino: 6.560957217516261e-07\n",
      "Epoch 562: perda treino: 6.543215818055614e-07\n",
      "Epoch 563: perda treino: 6.526443030452356e-07\n",
      "Epoch 564: perda treino: 6.50966910598072e-07\n",
      "Epoch 565: perda treino: 6.493057185252837e-07\n",
      "Epoch 566: perda treino: 6.476122393905825e-07\n",
      "Epoch 567: perda treino: 6.459188170993002e-07\n",
      "Epoch 568: perda treino: 6.442899120884249e-07\n",
      "Epoch 569: perda treino: 6.426931236092059e-07\n",
      "Epoch 570: perda treino: 6.411529511751723e-07\n",
      "Epoch 571: perda treino: 6.394271281351394e-07\n",
      "Epoch 572: perda treino: 6.377579211402917e-07\n",
      "Epoch 573: perda treino: 6.361289592859976e-07\n",
      "Epoch 574: perda treino: 6.344436656036123e-07\n",
      "Epoch 575: perda treino: 6.328307904368558e-07\n",
      "Epoch 576: perda treino: 6.312663458629686e-07\n",
      "Epoch 577: perda treino: 6.295890671026427e-07\n",
      "Epoch 578: perda treino: 6.27847214218491e-07\n",
      "Epoch 579: perda treino: 6.262182523641968e-07\n",
      "Epoch 580: perda treino: 6.245732606657839e-07\n",
      "Epoch 581: perda treino: 6.23049118075869e-07\n",
      "Epoch 582: perda treino: 6.213717824721243e-07\n",
      "Epoch 583: perda treino: 6.198799837875413e-07\n",
      "Epoch 584: perda treino: 6.184365020089899e-07\n",
      "Epoch 585: perda treino: 6.167591664052452e-07\n",
      "Epoch 586: perda treino: 6.151786351438204e-07\n",
      "Epoch 587: perda treino: 6.136947945378779e-07\n",
      "Epoch 588: perda treino: 6.120819762145402e-07\n",
      "Epoch 589: perda treino: 6.105015017965343e-07\n",
      "Epoch 590: perda treino: 6.090580200179829e-07\n",
      "Epoch 591: perda treino: 6.075338774280681e-07\n",
      "Epoch 592: perda treino: 6.060017767595127e-07\n",
      "Epoch 593: perda treino: 6.044614906386414e-07\n",
      "Epoch 594: perda treino: 6.029939072504931e-07\n",
      "Epoch 595: perda treino: 6.015261533320881e-07\n",
      "Epoch 596: perda treino: 5.999536938361416e-07\n",
      "Epoch 597: perda treino: 5.984779818390962e-07\n",
      "Epoch 598: perda treino: 5.970023266854696e-07\n",
      "Epoch 599: perda treino: 5.9555077314144e-07\n",
      "Epoch 600: perda treino: 5.940105438639876e-07\n",
      "Epoch 601: perda treino: 5.925429036324203e-07\n",
      "Epoch 602: perda treino: 5.909300853090826e-07\n",
      "Epoch 603: perda treino: 5.895511208109383e-07\n",
      "Epoch 604: perda treino: 5.880916091882682e-07\n",
      "Epoch 605: perda treino: 5.867368031431397e-07\n",
      "Epoch 606: perda treino: 5.852610911460943e-07\n",
      "Epoch 607: perda treino: 5.838579681949341e-07\n",
      "Epoch 608: perda treino: 5.824306299473392e-07\n",
      "Epoch 609: perda treino: 5.809710614812502e-07\n",
      "Epoch 610: perda treino: 5.796646860289911e-07\n",
      "Epoch 611: perda treino: 5.781969889540051e-07\n",
      "Epoch 612: perda treino: 5.768100095338013e-07\n",
      "Epoch 613: perda treino: 5.753343543801748e-07\n",
      "Epoch 614: perda treino: 5.74003763631481e-07\n",
      "Epoch 615: perda treino: 5.725522669308702e-07\n",
      "Epoch 616: perda treino: 5.712216761821765e-07\n",
      "Epoch 617: perda treino: 5.69745964185131e-07\n",
      "Epoch 618: perda treino: 5.684315738108126e-07\n",
      "Epoch 619: perda treino: 5.670364657817117e-07\n",
      "Epoch 620: perda treino: 5.656978032675397e-07\n",
      "Epoch 621: perda treino: 5.643834128932212e-07\n",
      "Epoch 622: perda treino: 5.629722181765828e-07\n",
      "Epoch 623: perda treino: 5.616658995677426e-07\n",
      "Epoch 624: perda treino: 5.602949499916576e-07\n",
      "Epoch 625: perda treino: 5.590128466792521e-07\n",
      "Epoch 626: perda treino: 5.576338821811078e-07\n",
      "Epoch 627: perda treino: 5.562710612139199e-07\n",
      "Epoch 628: perda treino: 5.547631189983804e-07\n",
      "Epoch 629: perda treino: 5.535777063414571e-07\n",
      "Epoch 630: perda treino: 5.521746402337158e-07\n",
      "Epoch 631: perda treino: 5.50876279703516e-07\n",
      "Epoch 632: perda treino: 5.495861046256323e-07\n",
      "Epoch 633: perda treino: 5.483200880007644e-07\n",
      "Epoch 634: perda treino: 5.471426902659005e-07\n",
      "Epoch 635: perda treino: 5.458363716570602e-07\n",
      "Epoch 636: perda treino: 5.444412636279594e-07\n",
      "Epoch 637: perda treino: 5.43223620752542e-07\n",
      "Epoch 638: perda treino: 5.419656190497335e-07\n",
      "Epoch 639: perda treino: 5.40618998456921e-07\n",
      "Epoch 640: perda treino: 5.394577442530135e-07\n",
      "Epoch 641: perda treino: 5.382078711591021e-07\n",
      "Epoch 642: perda treino: 5.3686920864493e-07\n",
      "Epoch 643: perda treino: 5.356838528314256e-07\n",
      "Epoch 644: perda treino: 5.344338660506764e-07\n",
      "Epoch 645: perda treino: 5.33159891347168e-07\n",
      "Epoch 646: perda treino: 5.319421916283318e-07\n",
      "Epoch 647: perda treino: 5.306922616910015e-07\n",
      "Epoch 648: perda treino: 5.29474675659003e-07\n",
      "Epoch 649: perda treino: 5.281602284412656e-07\n",
      "Epoch 650: perda treino: 5.268135510050342e-07\n",
      "Epoch 651: perda treino: 5.257087423160556e-07\n",
      "Epoch 652: perda treino: 5.244991712061164e-07\n",
      "Epoch 653: perda treino: 5.232976718616555e-07\n",
      "Epoch 654: perda treino: 5.221203309702105e-07\n",
      "Epoch 655: perda treino: 5.209349183132872e-07\n",
      "Epoch 656: perda treino: 5.19693116984854e-07\n",
      "Epoch 657: perda treino: 5.185157760934089e-07\n",
      "Epoch 658: perda treino: 5.173465069674421e-07\n",
      "Epoch 659: perda treino: 5.162175398254476e-07\n",
      "Epoch 660: perda treino: 5.14991825184552e-07\n",
      "Epoch 661: perda treino: 5.138145411365258e-07\n",
      "Epoch 662: perda treino: 5.126209998707054e-07\n",
      "Epoch 663: perda treino: 5.114275154483039e-07\n",
      "Epoch 664: perda treino: 5.103227636027441e-07\n",
      "Epoch 665: perda treino: 5.091616230856744e-07\n",
      "Epoch 666: perda treino: 5.079036782262847e-07\n",
      "Epoch 667: perda treino: 5.067505526312743e-07\n",
      "Epoch 668: perda treino: 5.056699592387304e-07\n",
      "Epoch 669: perda treino: 5.045329771746765e-07\n",
      "Epoch 670: perda treino: 5.033717798141879e-07\n",
      "Epoch 671: perda treino: 5.021863671572646e-07\n",
      "Epoch 672: perda treino: 5.010171548747167e-07\n",
      "Epoch 673: perda treino: 4.999043312636786e-07\n",
      "Epoch 674: perda treino: 4.988156092622376e-07\n",
      "Epoch 675: perda treino: 4.977109142600966e-07\n",
      "Epoch 676: perda treino: 4.966383926330309e-07\n",
      "Epoch 677: perda treino: 4.955981580678781e-07\n",
      "Epoch 678: perda treino: 4.944450324728678e-07\n",
      "Epoch 679: perda treino: 4.933161221742921e-07\n",
      "Epoch 680: perda treino: 4.921307095173688e-07\n",
      "Epoch 681: perda treino: 4.910662596557813e-07\n",
      "Epoch 682: perda treino: 4.900260250906285e-07\n",
      "Epoch 683: perda treino: 4.889292881671281e-07\n",
      "Epoch 684: perda treino: 4.877762194155366e-07\n",
      "Epoch 685: perda treino: 4.867279130849056e-07\n",
      "Epoch 686: perda treino: 4.855828024119546e-07\n",
      "Epoch 687: perda treino: 4.845747980652959e-07\n",
      "Epoch 688: perda treino: 4.834781748286332e-07\n",
      "Epoch 689: perda treino: 4.823734229830734e-07\n",
      "Epoch 690: perda treino: 4.814057774638059e-07\n",
      "Epoch 691: perda treino: 4.803090973837243e-07\n",
      "Epoch 692: perda treino: 4.791559149452951e-07\n",
      "Epoch 693: perda treino: 4.780835070050671e-07\n",
      "Epoch 694: perda treino: 4.771480917042936e-07\n",
      "Epoch 695: perda treino: 4.760836134209967e-07\n",
      "Epoch 696: perda treino: 4.750836808398162e-07\n",
      "Epoch 697: perda treino: 4.7404344627466344e-07\n",
      "Epoch 698: perda treino: 4.7293869442910363e-07\n",
      "Epoch 699: perda treino: 4.719790922536049e-07\n",
      "Epoch 700: perda treino: 4.7097915967242443e-07\n",
      "Epoch 701: perda treino: 4.6992286684144347e-07\n",
      "Epoch 702: perda treino: 4.6895516447875707e-07\n",
      "Epoch 703: perda treino: 4.679471885538078e-07\n",
      "Epoch 704: perda treino: 4.6695532773810555e-07\n",
      "Epoch 705: perda treino: 4.6592313651672157e-07\n",
      "Epoch 706: perda treino: 4.6482648485834943e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 707: perda treino: 4.638749260266195e-07\n",
      "Epoch 708: perda treino: 4.6283471988317615e-07\n",
      "Epoch 709: perda treino: 4.619315632226062e-07\n",
      "Epoch 710: perda treino: 4.609800328125857e-07\n",
      "Epoch 711: perda treino: 4.5998817199688347e-07\n",
      "Epoch 712: perda treino: 4.589882678374124e-07\n",
      "Epoch 713: perda treino: 4.5803673742739193e-07\n",
      "Epoch 714: perda treino: 4.570287330807332e-07\n",
      "Epoch 715: perda treino: 4.5602880049955274e-07\n",
      "Epoch 716: perda treino: 4.549886227778188e-07\n",
      "Epoch 717: perda treino: 4.540290206023201e-07\n",
      "Epoch 718: perda treino: 4.5313390728551894e-07\n",
      "Epoch 719: perda treino: 4.521097878296132e-07\n",
      "Epoch 720: perda treino: 4.51182444294318e-07\n",
      "Epoch 721: perda treino: 4.502228705405287e-07\n",
      "Epoch 722: perda treino: 4.4923908149030467e-07\n",
      "Epoch 723: perda treino: 4.4834399659521296e-07\n",
      "Epoch 724: perda treino: 4.4734412085745134e-07\n",
      "Epoch 725: perda treino: 4.4644093577517197e-07\n",
      "Epoch 726: perda treino: 4.4540075805343804e-07\n",
      "Epoch 727: perda treino: 4.444895012056804e-07\n",
      "Epoch 728: perda treino: 4.4361053141983575e-07\n",
      "Epoch 729: perda treino: 4.4261057041694585e-07\n",
      "Epoch 730: perda treino: 4.4163490997561894e-07\n",
      "Epoch 731: perda treino: 4.40731753315049e-07\n",
      "Epoch 732: perda treino: 4.3982055331071024e-07\n",
      "Epoch 733: perda treino: 4.389254684156185e-07\n",
      "Epoch 734: perda treino: 4.380303835205268e-07\n",
      "Epoch 735: perda treino: 4.371111117507098e-07\n",
      "Epoch 736: perda treino: 4.362160268556181e-07\n",
      "Epoch 737: perda treino: 4.352402811491629e-07\n",
      "Epoch 738: perda treino: 4.343935984252312e-07\n",
      "Epoch 739: perda treino: 4.334340246714419e-07\n",
      "Epoch 740: perda treino: 4.3256312665107544e-07\n",
      "Epoch 741: perda treino: 4.316196964282426e-07\n",
      "Epoch 742: perda treino: 4.3068428112746915e-07\n",
      "Epoch 743: perda treino: 4.298295266380592e-07\n",
      "Epoch 744: perda treino: 4.29031217663578e-07\n",
      "Epoch 745: perda treino: 4.281441761122551e-07\n",
      "Epoch 746: perda treino: 4.2723291926449747e-07\n",
      "Epoch 747: perda treino: 4.26410423415291e-07\n",
      "Epoch 748: perda treino: 4.2549922341095225e-07\n",
      "Epoch 749: perda treino: 4.2461218185962935e-07\n",
      "Epoch 750: perda treino: 4.2377357090117584e-07\n",
      "Epoch 751: perda treino: 4.2278981027266127e-07\n",
      "Epoch 752: perda treino: 4.2192698401777307e-07\n",
      "Epoch 753: perda treino: 4.2111255993404484e-07\n",
      "Epoch 754: perda treino: 4.202336185699096e-07\n",
      "Epoch 755: perda treino: 4.19386879002559e-07\n",
      "Epoch 756: perda treino: 4.1841116171781323e-07\n",
      "Epoch 757: perda treino: 4.1761288116504147e-07\n",
      "Epoch 758: perda treino: 4.1675002648844384e-07\n",
      "Epoch 759: perda treino: 4.1591945887375914e-07\n",
      "Epoch 760: perda treino: 4.150082872911298e-07\n",
      "Epoch 761: perda treino: 4.1425028030062094e-07\n",
      "Epoch 762: perda treino: 4.13460043091618e-07\n",
      "Epoch 763: perda treino: 4.12605288602208e-07\n",
      "Epoch 764: perda treino: 4.118311665024521e-07\n",
      "Epoch 765: perda treino: 4.1096831182585447e-07\n",
      "Epoch 766: perda treino: 4.102425634755491e-07\n",
      "Epoch 767: perda treino: 4.093958239081985e-07\n",
      "Epoch 768: perda treino: 4.086136584646738e-07\n",
      "Epoch 769: perda treino: 4.078556514741649e-07\n",
      "Epoch 770: perda treino: 4.069847818755079e-07\n",
      "Epoch 771: perda treino: 4.062751486344496e-07\n",
      "Epoch 772: perda treino: 4.0545268120695255e-07\n",
      "Epoch 773: perda treino: 4.046382287015149e-07\n",
      "Epoch 774: perda treino: 4.03880221711006e-07\n",
      "Epoch 775: perda treino: 4.030818843148154e-07\n",
      "Epoch 776: perda treino: 4.021868278414331e-07\n",
      "Epoch 777: perda treino: 4.0142882085092424e-07\n",
      "Epoch 778: perda treino: 4.006386120636307e-07\n",
      "Epoch 779: perda treino: 3.9984030308914953e-07\n",
      "Epoch 780: perda treino: 3.9899356352179893e-07\n",
      "Epoch 781: perda treino: 3.982356133747089e-07\n",
      "Epoch 782: perda treino: 3.9741311752550246e-07\n",
      "Epoch 783: perda treino: 3.9659869344177423e-07\n",
      "Epoch 784: perda treino: 3.9580842781106185e-07\n",
      "Epoch 785: perda treino: 3.951068379137723e-07\n",
      "Epoch 786: perda treino: 3.9428434206456586e-07\n",
      "Epoch 787: perda treino: 3.934538028715906e-07\n",
      "Epoch 788: perda treino: 3.926554654754e-07\n",
      "Epoch 789: perda treino: 3.9184908473544056e-07\n",
      "Epoch 790: perda treino: 3.9110722127588815e-07\n",
      "Epoch 791: perda treino: 3.903330707544228e-07\n",
      "Epoch 792: perda treino: 3.896154225913051e-07\n",
      "Epoch 793: perda treino: 3.8879292674209864e-07\n",
      "Epoch 794: perda treino: 3.880672068135027e-07\n",
      "Epoch 795: perda treino: 3.8733344354113797e-07\n",
      "Epoch 796: perda treino: 3.8654314948871615e-07\n",
      "Epoch 797: perda treino: 3.858335730910767e-07\n",
      "Epoch 798: perda treino: 3.850997529752931e-07\n",
      "Epoch 799: perda treino: 3.8433364579759655e-07\n",
      "Epoch 800: perda treino: 3.8364825627468235e-07\n",
      "Epoch 801: perda treino: 3.8286609083115763e-07\n",
      "Epoch 802: perda treino: 3.821241989498958e-07\n",
      "Epoch 803: perda treino: 3.8136622038109635e-07\n",
      "Epoch 804: perda treino: 3.8068080243647273e-07\n",
      "Epoch 805: perda treino: 3.799308956331515e-07\n",
      "Epoch 806: perda treino: 3.792132474700338e-07\n",
      "Epoch 807: perda treino: 3.784794273542502e-07\n",
      "Epoch 808: perda treino: 3.7766494642710313e-07\n",
      "Epoch 809: perda treino: 3.769392264985072e-07\n",
      "Epoch 810: perda treino: 3.7616507597704185e-07\n",
      "Epoch 811: perda treino: 3.7547965803241823e-07\n",
      "Epoch 812: perda treino: 3.747055359326623e-07\n",
      "Epoch 813: perda treino: 3.740040313005011e-07\n",
      "Epoch 814: perda treino: 3.7330244140321156e-07\n",
      "Epoch 815: perda treino: 3.7267349739522615e-07\n",
      "Epoch 816: perda treino: 3.7202033809080604e-07\n",
      "Epoch 817: perda treino: 3.712946181622101e-07\n",
      "Epoch 818: perda treino: 3.7058498492115177e-07\n",
      "Epoch 819: perda treino: 3.6981086282139586e-07\n",
      "Epoch 820: perda treino: 3.69181890391701e-07\n",
      "Epoch 821: perda treino: 3.6842391182290157e-07\n",
      "Epoch 822: perda treino: 3.677143070035527e-07\n",
      "Epoch 823: perda treino: 3.6705310435536376e-07\n",
      "Epoch 824: perda treino: 3.662950973648549e-07\n",
      "Epoch 825: perda treino: 3.6556937743625895e-07\n",
      "Epoch 826: perda treino: 3.649404050065641e-07\n",
      "Epoch 827: perda treino: 3.641662829068082e-07\n",
      "Epoch 828: perda treino: 3.635211953678663e-07\n",
      "Epoch 829: perda treino: 3.627873752520827e-07\n",
      "Epoch 830: perda treino: 3.6207779885444324e-07\n",
      "Epoch 831: perda treino: 3.613923809098196e-07\n",
      "Epoch 832: perda treino: 3.6070693454348657e-07\n",
      "Epoch 833: perda treino: 3.6001347325509414e-07\n",
      "Epoch 834: perda treino: 3.594329029965593e-07\n",
      "Epoch 835: perda treino: 3.5872326975550095e-07\n",
      "Epoch 836: perda treino: 3.5802170827992086e-07\n",
      "Epoch 837: perda treino: 3.5734433367906604e-07\n",
      "Epoch 838: perda treino: 3.5671538967108063e-07\n",
      "Epoch 839: perda treino: 3.561267192253581e-07\n",
      "Epoch 840: perda treino: 3.55473559920938e-07\n",
      "Epoch 841: perda treino: 3.547881703980238e-07\n",
      "Epoch 842: perda treino: 3.541188675626472e-07\n",
      "Epoch 843: perda treino: 3.5344959314898006e-07\n",
      "Epoch 844: perda treino: 3.5280447718832875e-07\n",
      "Epoch 845: perda treino: 3.521110158999363e-07\n",
      "Epoch 846: perda treino: 3.5150623034496675e-07\n",
      "Epoch 847: perda treino: 3.5089337302451895e-07\n",
      "Epoch 848: perda treino: 3.502644005948241e-07\n",
      "Epoch 849: perda treino: 3.4961934147759166e-07\n",
      "Epoch 850: perda treino: 3.488774495963298e-07\n",
      "Epoch 851: perda treino: 3.482565489321132e-07\n",
      "Epoch 852: perda treino: 3.4758727451844607e-07\n",
      "Epoch 853: perda treino: 3.469583020887512e-07\n",
      "Epoch 854: perda treino: 3.464018902832322e-07\n",
      "Epoch 855: perda treino: 3.457568027442903e-07\n",
      "Epoch 856: perda treino: 3.4514397384555195e-07\n",
      "Epoch 857: perda treino: 3.445391882905824e-07\n",
      "Epoch 858: perda treino: 3.4387798564239347e-07\n",
      "Epoch 859: perda treino: 3.433135020713962e-07\n",
      "Epoch 860: perda treino: 3.4266841453245434e-07\n",
      "Epoch 861: perda treino: 3.4201528364974365e-07\n",
      "Epoch 862: perda treino: 3.4132980886170117e-07\n",
      "Epoch 863: perda treino: 3.4069282150994695e-07\n",
      "Epoch 864: perda treino: 3.400879791115585e-07\n",
      "Epoch 865: perda treino: 3.3941063293241314e-07\n",
      "Epoch 866: perda treino: 3.3879780403367477e-07\n",
      "Epoch 867: perda treino: 3.3820111866589286e-07\n",
      "Epoch 868: perda treino: 3.3768500884434616e-07\n",
      "Epoch 869: perda treino: 3.3701570600896957e-07\n",
      "Epoch 870: perda treino: 3.3634646001701185e-07\n",
      "Epoch 871: perda treino: 3.3575781799299875e-07\n",
      "Epoch 872: perda treino: 3.351691475472762e-07\n",
      "Epoch 873: perda treino: 3.345724337577849e-07\n",
      "Epoch 874: perda treino: 3.3405638077965705e-07\n",
      "Epoch 875: perda treino: 3.3337903460051166e-07\n",
      "Epoch 876: perda treino: 3.327822923893109e-07\n",
      "Epoch 877: perda treino: 3.3217750683434133e-07\n",
      "Epoch 878: perda treino: 3.316372669814882e-07\n",
      "Epoch 879: perda treino: 3.310325098482281e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 880: perda treino: 3.30347063481895e-07\n",
      "Epoch 881: perda treino: 3.297181194739096e-07\n",
      "Epoch 882: perda treino: 3.291455357157247e-07\n",
      "Epoch 883: perda treino: 3.2857303722266806e-07\n",
      "Epoch 884: perda treino: 3.280811711192655e-07\n",
      "Epoch 885: perda treino: 3.2748445732977416e-07\n",
      "Epoch 886: perda treino: 3.2699256280466216e-07\n",
      "Epoch 887: perda treino: 3.2629100132908206e-07\n",
      "Epoch 888: perda treino: 3.256701290865749e-07\n",
      "Epoch 889: perda treino: 3.251217890465341e-07\n",
      "Epoch 890: perda treino: 3.246218511776533e-07\n",
      "Epoch 891: perda treino: 3.240089938572055e-07\n",
      "Epoch 892: perda treino: 3.234767973481212e-07\n",
      "Epoch 893: perda treino: 3.228317098091793e-07\n",
      "Epoch 894: perda treino: 3.2234788704954553e-07\n",
      "Epoch 895: perda treino: 3.216544257611531e-07\n",
      "Epoch 896: perda treino: 3.2112217240864993e-07\n",
      "Epoch 897: perda treino: 3.2042873954196693e-07\n",
      "Epoch 898: perda treino: 3.198400690962444e-07\n",
      "Epoch 899: perda treino: 3.1929175747791305e-07\n",
      "Epoch 900: perda treino: 3.1875151762505993e-07\n",
      "Epoch 901: perda treino: 3.182595946782385e-07\n",
      "Epoch 902: perda treino: 3.17735441512923e-07\n",
      "Epoch 903: perda treino: 3.171467994889099e-07\n",
      "Epoch 904: perda treino: 3.164774966535333e-07\n",
      "Epoch 905: perda treino: 3.159372568006802e-07\n",
      "Epoch 906: perda treino: 3.153163561364636e-07\n",
      "Epoch 907: perda treino: 3.1477608786190103e-07\n",
      "Epoch 908: perda treino: 3.14268078227542e-07\n",
      "Epoch 909: perda treino: 3.1371166642202297e-07\n",
      "Epoch 910: perda treino: 3.1315525461650395e-07\n",
      "Epoch 911: perda treino: 3.1259082788892556e-07\n",
      "Epoch 912: perda treino: 3.120425162705942e-07\n",
      "Epoch 913: perda treino: 3.1143775913733407e-07\n",
      "Epoch 914: perda treino: 3.108974908627715e-07\n",
      "Epoch 915: perda treino: 3.103410790572525e-07\n",
      "Epoch 916: perda treino: 3.098088825481682e-07\n",
      "Epoch 917: perda treino: 3.093250597885344e-07\n",
      "Epoch 918: perda treino: 3.087606046392466e-07\n",
      "Epoch 919: perda treino: 3.0824455166111875e-07\n",
      "Epoch 920: perda treino: 3.07663924559165e-07\n",
      "Epoch 921: perda treino: 3.0708332587892073e-07\n",
      "Epoch 922: perda treino: 3.065995315409964e-07\n",
      "Epoch 923: perda treino: 3.0615603918704437e-07\n",
      "Epoch 924: perda treino: 3.0556739716303127e-07\n",
      "Epoch 925: perda treino: 3.0509968951264455e-07\n",
      "Epoch 926: perda treino: 3.045271625978785e-07\n",
      "Epoch 927: perda treino: 3.039143336991401e-07\n",
      "Epoch 928: perda treino: 3.0337403700286814e-07\n",
      "Epoch 929: perda treino: 3.0278542340056447e-07\n",
      "Epoch 930: perda treino: 3.023016006409307e-07\n",
      "Epoch 931: perda treino: 3.017774474756152e-07\n",
      "Epoch 932: perda treino: 3.013178115907067e-07\n",
      "Epoch 933: perda treino: 3.007856435033318e-07\n",
      "Epoch 934: perda treino: 3.002130881668563e-07\n",
      "Epoch 935: perda treino: 2.99729293828932e-07\n",
      "Epoch 936: perda treino: 2.992374277255294e-07\n",
      "Epoch 937: perda treino: 2.987132745602139e-07\n",
      "Epoch 938: perda treino: 2.982858688937995e-07\n",
      "Epoch 939: perda treino: 2.9776981591567164e-07\n",
      "Epoch 940: perda treino: 2.9723761940658733e-07\n",
      "Epoch 941: perda treino: 2.9668123602277774e-07\n",
      "Epoch 942: perda treino: 2.9618129815389693e-07\n",
      "Epoch 943: perda treino: 2.9574587756542314e-07\n",
      "Epoch 944: perda treino: 2.953507021175028e-07\n",
      "Epoch 945: perda treino: 2.9481043384294026e-07\n",
      "Epoch 946: perda treino: 2.9427019399008714e-07\n",
      "Epoch 947: perda treino: 2.937057104190899e-07\n",
      "Epoch 948: perda treino: 2.9316547056623676e-07\n",
      "Epoch 949: perda treino: 2.927380933215318e-07\n",
      "Epoch 950: perda treino: 2.9219782504696923e-07\n",
      "Epoch 951: perda treino: 2.916736718816537e-07\n",
      "Epoch 952: perda treino: 2.911898775437294e-07\n",
      "Epoch 953: perda treino: 2.907383134242991e-07\n",
      "Epoch 954: perda treino: 2.9019804514973657e-07\n",
      "Epoch 955: perda treino: 2.897384376865375e-07\n",
      "Epoch 956: perda treino: 2.893432906603266e-07\n",
      "Epoch 957: perda treino: 2.889401287120563e-07\n",
      "Epoch 958: perda treino: 2.883837169065373e-07\n",
      "Epoch 959: perda treino: 2.8791603767786e-07\n",
      "Epoch 960: perda treino: 2.8749673219863325e-07\n",
      "Epoch 961: perda treino: 2.8693227704934543e-07\n",
      "Epoch 962: perda treino: 2.864565260551899e-07\n",
      "Epoch 963: perda treino: 2.859726748738467e-07\n",
      "Epoch 964: perda treino: 2.854727370049659e-07\n",
      "Epoch 965: perda treino: 2.8499698601081036e-07\n",
      "Epoch 966: perda treino: 2.8450509148569836e-07\n",
      "Epoch 967: perda treino: 2.841019295374281e-07\n",
      "Epoch 968: perda treino: 2.83513287513415e-07\n",
      "Epoch 969: perda treino: 2.8310202537795703e-07\n",
      "Epoch 970: perda treino: 2.8262630280551093e-07\n",
      "Epoch 971: perda treino: 2.82166638498893e-07\n",
      "Epoch 972: perda treino: 2.8165058552076516e-07\n",
      "Epoch 973: perda treino: 2.8119094963585667e-07\n",
      "Epoch 974: perda treino: 2.807635723911517e-07\n",
      "Epoch 975: perda treino: 2.8024751941302384e-07\n",
      "Epoch 976: perda treino: 2.7973143801318656e-07\n",
      "Epoch 977: perda treino: 2.7927984547204687e-07\n",
      "Epoch 978: perda treino: 2.788121662433696e-07\n",
      "Epoch 979: perda treino: 2.7824771109408175e-07\n",
      "Epoch 980: perda treino: 2.778606642550585e-07\n",
      "Epoch 981: perda treino: 2.7744943054131e-07\n",
      "Epoch 982: perda treino: 2.7700590976564854e-07\n",
      "Epoch 983: perda treino: 2.7649792855299893e-07\n",
      "Epoch 984: perda treino: 2.760947381830192e-07\n",
      "Epoch 985: perda treino: 2.756028436579072e-07\n",
      "Epoch 986: perda treino: 2.751271210854611e-07\n",
      "Epoch 987: perda treino: 2.746594418567838e-07\n",
      "Epoch 988: perda treino: 2.742884817052982e-07\n",
      "Epoch 989: perda treino: 2.7377242872717034e-07\n",
      "Epoch 990: perda treino: 2.7335309482623416e-07\n",
      "Epoch 991: perda treino: 2.729418326907762e-07\n",
      "Epoch 992: perda treino: 2.7242577971264836e-07\n",
      "Epoch 993: perda treino: 2.7196614382773987e-07\n",
      "Epoch 994: perda treino: 2.716274707381672e-07\n",
      "Epoch 995: perda treino: 2.7115171974401164e-07\n",
      "Epoch 996: perda treino: 2.706517534534214e-07\n",
      "Epoch 997: perda treino: 2.7019214599022234e-07\n",
      "Epoch 998: perda treino: 2.6977281208928616e-07\n",
      "Epoch 999: perda treino: 2.6939383701574116e-07\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "y_pred = model(featuresEdges_treino)\n",
    "train_data.edge_label = torch.reshape(train_data.edge_label,(-1,1))\n",
    "\n",
    "antes_treino = criterion(y_pred, train_data.edge_label) \n",
    "\n",
    "print('Teste - perda antes do treinamento' , antes_treino.item())\n",
    "\n",
    "model.train()\n",
    "epoch = 1000\n",
    "\n",
    "for epoch in range(epoch):\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # Passe Forward\n",
    "    y_pred = model(featuresEdges_treino)\n",
    "    \n",
    "    # Computa a perda\n",
    "    loss = criterion(y_pred, train_data.edge_label)\n",
    "    \n",
    "    print('Epoch {}: perda treino: {}'.format(epoch, loss.item()))\n",
    "    \n",
    "    # Passe de Backward\n",
    "    loss.backward()\n",
    "    optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7345230340738079\n",
      "0.7071362372567193\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "y_pred = model(featuresEdges_teste)\n",
    "y_pred = torch.reshape(y_pred,(-1,1))\n",
    "\n",
    "threshold = torch.tensor([0.5]).to(\"cpu\")\n",
    "\n",
    "#Atribui 0 ou 1 de acordo com o threshold\n",
    "results = (y_pred>threshold).float()*1\n",
    "\n",
    "#reshape\n",
    "test_data.edge_label = torch.reshape(test_data.edge_label,(-1,1))\n",
    "\n",
    "#Area under the curve - AUC\n",
    "print(roc_auc_score(test_data.edge_label.cpu(),  y_pred.detach().numpy()))\n",
    "\n",
    "#Computes - F1 score\n",
    "print(f1_score(test_data.edge_label.cpu(),results.cpu()))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gnn",
   "language": "python",
   "name": "gnn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
